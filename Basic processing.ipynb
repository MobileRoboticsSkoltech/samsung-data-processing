{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da669a4-f30b-4d57-b340-c283502ab356",
   "metadata": {},
   "source": [
    "### Basic processing of Samsung data from Azure cameras\n",
    "\n",
    "It includes undistortion of color and depth images and reprojection of depth image to undistrorted color virtual camera.\n",
    "\n",
    "Parameters to set: `SEQUENCE_PATH` - path for recorded sequence, `OUTPUT_DIR` - where postprocessed data will be located.\n",
    "\n",
    "**Attention**: calibration file `calib_params.yaml` for every camera should be located in original camera data directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d3a173-38a2-4b7a-abb4-82f2a85dc42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-06-18 19:32:50,469 - utils - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO - 2022-06-18 19:32:50,470 - utils - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.calib_io_utils import load_azure_params\n",
    "from utils.cv_utils import undistort_image, reproject_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26e668be-ceda-4694-9514-a595d16f4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_PATH = '/home/anasyasiia/Downloads/2022-04-16-12-15-47_round0/2022-04-16-12-15-47_round0/'\n",
    "OUTPUT_DIR = 'output'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccca8bf-0dcb-470f-a622-8dc60075de6c",
   "metadata": {},
   "source": [
    "### List recorded cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4862016-0023-4752-818e-2cf4707e399f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3m', '5s']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_names = os.listdir(SEQUENCE_PATH)\n",
    "camera_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b394bb3-aab5-4209-80d8-68fbb71f8153",
   "metadata": {},
   "source": [
    "### Prepare infrastructure for postprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc3e95d-26af-4aea-a2d5-b5489a6c5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_basedir = os.path.basename(os.path.normpath(SEQUENCE_PATH))\n",
    "postprocessed_data_dir = os.path.join(OUTPUT_DIR, dataset_basedir)\n",
    "\n",
    "if os.path.exists(postprocessed_data_dir):\n",
    "    shutil.rmtree(postprocessed_data_dir)\n",
    "    \n",
    "os.mkdir(postprocessed_data_dir)\n",
    "\n",
    "for camera_name in camera_names:\n",
    "    os.mkdir(os.path.join(postprocessed_data_dir, camera_name))\n",
    "    os.mkdir(os.path.join(postprocessed_data_dir, camera_name, 'color'))\n",
    "    os.mkdir(os.path.join(postprocessed_data_dir, camera_name, 'depth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0556619-dc87-41d3-b6ba-fa78c5e41b91",
   "metadata": {},
   "source": [
    "### Iterate over cameras and do undistortion and reprojection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7364fda-9a92-4608-a4e5-17e6888afa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 114/1699 [01:50<44:15,  1.68s/it]"
     ]
    }
   ],
   "source": [
    "for camera_name in camera_names:\n",
    "    camera_data_path = os.path.join(SEQUENCE_PATH, camera_name)\n",
    "    azure_calib_path = os.path.join(camera_data_path, 'calib_params.json')\n",
    "\n",
    "    color_camera, depth_camera, T_depth2color = load_azure_params(azure_calib_path)\n",
    "\n",
    "    color_images_dir = os.path.join(camera_data_path, 'color')\n",
    "    color_image_names = os.listdir(color_images_dir)\n",
    "    color_image_names.sort()\n",
    "    postprocessed_color_dir = os.path.join(postprocessed_data_dir, camera_name, 'color')\n",
    "\n",
    "    for color_image_name in tqdm(color_image_names):\n",
    "        image = cv2.imread(os.path.join(color_images_dir, color_image_name), -1)\n",
    "        undistorted_image = undistort_image(image, color_camera)\n",
    "        imageio.imwrite(os.path.join(postprocessed_color_dir, color_image_name), image)\n",
    "\n",
    "    depth_images_dir = os.path.join(camera_data_path, 'depth')\n",
    "    depth_image_names = os.listdir(depth_images_dir)\n",
    "    depth_image_names.sort()\n",
    "    postprocessed_depth_dir = os.path.join(postprocessed_data_dir, camera_names, 'depth')\n",
    "\n",
    "    for depth_image_name in tqdm(depth_image_names):\n",
    "        image = cv2.imread(os.path.join(depth_images_dir, depth_image_name), -1)\n",
    "        undistorted_image = undistort_image(image, depth_camera)\n",
    "        reprojected_image = reproject_depth(undistorted_image, depth_camera, color_camera, T_depth2color)\n",
    "        imageio.imwrite(os.path.join(postprocessed_depth_dir, depth_image_name), reprojected_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
